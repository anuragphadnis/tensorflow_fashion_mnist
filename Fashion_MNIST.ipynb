{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanidhyamangal/tensorflow_fashion_mnist/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tdNX2otEffT2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST \n",
        "\n",
        "This notebooks defines how a CNN can be used to make a classifier which can be used to classify various clothes based on its images. \n",
        "\n",
        "Download the Fashion MNIST dataset from https://www.kaggle.com/zalando-research/fashionmnist/downloads/fashionmnist.zip/4\n",
        "\n",
        "Unzip the files. You should be able to view 2 csv files: fashion-mnist_train.csv and fashion-mnist_test.csv."
      ]
    },
    {
      "metadata": {
        "id": "G4SU3nRAffT6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Basic Imports"
      ]
    },
    {
      "metadata": {
        "id": "ZA_jlOdPffT8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # for matrix maths \n",
        "import itertools # for itertions \n",
        "import pandas as pd # for converting data into data tables \n",
        "import math # for maths \n",
        "\n",
        "# tensorflow import \n",
        "import tensorflow as tf \n",
        "\n",
        "# DataViz import\n",
        "import matplotlib.pyplot as plt # for plotting "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WV2u_6mnffUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "nX6_9SbEfkFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this section we are going to define some helper functions which are going to help us in formulating problem more easily\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2hh0KnNmgTEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper function for prediction \n",
        "\n",
        "This is an input function which is used by tensorflow evaluator to predict the image once our model is fully trained."
      ]
    },
    {
      "metadata": {
        "id": "2z8PtO42ffUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# helper function for predicting input\n",
        "def predict_input_fn(df):\n",
        "    def input_fun():\n",
        "        \n",
        "        # seperate pixels from labels \n",
        "        pixels = df.iloc[:,1:].as_matrix().astype(float)\n",
        "        labels = df.iloc[:,0].as_matrix().astype(float)\n",
        "        \n",
        "        # construct a tf data set \n",
        "        batch_pixels = tf.convert_to_tensor(pixels, tf.float32)\n",
        "        batch_labels = tf.convert_to_tensor(labels, tf.float32)\n",
        "        \n",
        "        return {'pixels':batch_pixels}, batch_labels\n",
        "    return input_fun"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZANvaKpg1zY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper function for Input \n",
        "\n",
        "This section contains a function which perform following operations:\n",
        "\n",
        "*   Shuffle's data set to increase variance\n",
        "*   Extract pixels and labels from the Pandas data frame\n",
        "*   Convert Extracted pixels and labels into tensors and make a one shot iterator\n",
        "\n",
        "It is a composite function to feed data into tensorflow evaluator."
      ]
    },
    {
      "metadata": {
        "id": "wANSRR9pgz8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def input function \n",
        "\n",
        "\n",
        "#@title Boilerplate Code for feeding the dataset into the Model (Can be skipped).\n",
        "\n",
        "def generate_input_fn(df, batch_size, num_epochs=None):\n",
        "    def input_fn():\n",
        "\n",
        "    # shuffle the rows.\n",
        "\n",
        "        shuffle_df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Separate the pixels from the labels.\n",
        "\n",
        "        pixels = shuffle_df.iloc[:, 1:].as_matrix().astype(float)\n",
        "\n",
        "        labels = shuffle_df.iloc[:, 0].as_matrix().astype(int)\n",
        "\n",
        "    # Construct tf.data.DataSet from the 2 numpy arrays.\n",
        "\n",
        "        pixels = tf.convert_to_tensor(pixels, dtype=tf.float32)\n",
        "\n",
        "        labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((pixels, labels))\n",
        "\n",
        "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
        "\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "        dataset = dataset.repeat(num_epochs)\n",
        "\n",
        "        # make one shot iterator for the data to be feed in evaluator\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "    \n",
        "\n",
        "        batch_pixels, batch_labels = iterator.get_next()\n",
        "\n",
        "    \n",
        "\n",
        "        return {\"pixels\": batch_pixels}, batch_labels\n",
        "    return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "haJlQ05qzR6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "01eebef4-403d-4b42-cdbe-def9d83ae705"
      },
      "cell_type": "code",
      "source": [
        "!wget https://gitlab.com/sanidhyamangal/datasets/raw/master/fashion-mnist_train.csv\n",
        "!wget https://gitlab.com/sanidhyamangal/datasets/raw/master/fashion-mnist_test.csv  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-03 05:27:13--  https://gitlab.com/sanidhyamangal/datasets/raw/master/fashion-mnist_train.csv\n",
            "Resolving gitlab.com (gitlab.com)... 35.231.145.151\n",
            "Connecting to gitlab.com (gitlab.com)|35.231.145.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133047193 (127M) [text/plain]\n",
            "Saving to: ‘fashion-mnist_train.csv’\n",
            "\n",
            "fashion-mnist_train 100%[===================>] 126.88M  65.6MB/s    in 1.9s    \n",
            "\n",
            "2019-02-03 05:27:16 (65.6 MB/s) - ‘fashion-mnist_train.csv’ saved [133047193/133047193]\n",
            "\n",
            "--2019-02-03 05:27:18--  https://gitlab.com/sanidhyamangal/datasets/raw/master/fashion-mnist_test.csv\n",
            "Resolving gitlab.com (gitlab.com)... 35.231.145.151\n",
            "Connecting to gitlab.com (gitlab.com)|35.231.145.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22176691 (21M) [text/plain]\n",
            "Saving to: ‘fashion-mnist_test.csv’\n",
            "\n",
            "fashion-mnist_test. 100%[===================>]  21.15M  35.5MB/s    in 0.6s    \n",
            "\n",
            "2019-02-03 05:27:19 (35.5 MB/s) - ‘fashion-mnist_test.csv’ saved [22176691/22176691]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ccF8js1QffUH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyse Dataset \n",
        "\n",
        "\n",
        "Load csv files in a form of pandas data frame"
      ]
    },
    {
      "metadata": {
        "id": "lskZLwMKffUI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert csv to data frames \n",
        "train_df = pd.read_csv('./fashion-mnist_train.csv') # train set \n",
        "test_df = pd.read_csv('./fashion-mnist_test.csv') # test set "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ByAab7ObffUM",
        "colab_type": "code",
        "outputId": "6de9afaa-6de4-4759-f92a-cec35b9efa92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "# describing labels of train set \n",
        "train_df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>60000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.035333</td>\n",
              "      <td>0.101933</td>\n",
              "      <td>0.247967</td>\n",
              "      <td>0.411467</td>\n",
              "      <td>0.805767</td>\n",
              "      <td>2.198283</td>\n",
              "      <td>5.682000</td>\n",
              "      <td>...</td>\n",
              "      <td>34.625400</td>\n",
              "      <td>23.300683</td>\n",
              "      <td>16.588267</td>\n",
              "      <td>17.869433</td>\n",
              "      <td>22.814817</td>\n",
              "      <td>17.911483</td>\n",
              "      <td>8.520633</td>\n",
              "      <td>2.753300</td>\n",
              "      <td>0.855517</td>\n",
              "      <td>0.07025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.872305</td>\n",
              "      <td>0.094689</td>\n",
              "      <td>0.271011</td>\n",
              "      <td>1.222324</td>\n",
              "      <td>2.452871</td>\n",
              "      <td>4.306912</td>\n",
              "      <td>5.836188</td>\n",
              "      <td>8.215169</td>\n",
              "      <td>14.093378</td>\n",
              "      <td>23.819481</td>\n",
              "      <td>...</td>\n",
              "      <td>57.545242</td>\n",
              "      <td>48.854427</td>\n",
              "      <td>41.979611</td>\n",
              "      <td>43.966032</td>\n",
              "      <td>51.830477</td>\n",
              "      <td>45.149388</td>\n",
              "      <td>29.614859</td>\n",
              "      <td>17.397652</td>\n",
              "      <td>9.356960</td>\n",
              "      <td>2.12587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>224.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>170.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
              "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
              "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
              "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
              "\n",
              "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
              "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
              "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
              "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
              "\n",
              "          ...           pixel775      pixel776      pixel777      pixel778  \\\n",
              "count     ...       60000.000000  60000.000000  60000.000000  60000.000000   \n",
              "mean      ...          34.625400     23.300683     16.588267     17.869433   \n",
              "std       ...          57.545242     48.854427     41.979611     43.966032   \n",
              "min       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "25%       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "50%       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "75%       ...          58.000000      9.000000      0.000000      0.000000   \n",
              "max       ...         255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
              "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
              "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
              "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "          pixel784  \n",
              "count  60000.00000  \n",
              "mean       0.07025  \n",
              "std        2.12587  \n",
              "min        0.00000  \n",
              "25%        0.00000  \n",
              "50%        0.00000  \n",
              "75%        0.00000  \n",
              "max      170.00000  \n",
              "\n",
              "[8 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "oP6CXxrwffUV",
        "colab_type": "code",
        "outputId": "9e8221d8-ad51-476a-be8b-40ea917663bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.052100</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.208600</td>\n",
              "      <td>0.349200</td>\n",
              "      <td>0.826700</td>\n",
              "      <td>2.321200</td>\n",
              "      <td>5.457800</td>\n",
              "      <td>...</td>\n",
              "      <td>34.320800</td>\n",
              "      <td>23.071900</td>\n",
              "      <td>16.432000</td>\n",
              "      <td>17.870600</td>\n",
              "      <td>22.860000</td>\n",
              "      <td>17.790200</td>\n",
              "      <td>8.353500</td>\n",
              "      <td>2.541600</td>\n",
              "      <td>0.629500</td>\n",
              "      <td>0.06560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.872425</td>\n",
              "      <td>0.024493</td>\n",
              "      <td>0.525187</td>\n",
              "      <td>2.494315</td>\n",
              "      <td>2.208882</td>\n",
              "      <td>4.669183</td>\n",
              "      <td>5.657849</td>\n",
              "      <td>8.591731</td>\n",
              "      <td>15.031508</td>\n",
              "      <td>23.359019</td>\n",
              "      <td>...</td>\n",
              "      <td>57.888679</td>\n",
              "      <td>49.049749</td>\n",
              "      <td>42.159665</td>\n",
              "      <td>44.140552</td>\n",
              "      <td>51.706601</td>\n",
              "      <td>45.128107</td>\n",
              "      <td>28.765769</td>\n",
              "      <td>16.417363</td>\n",
              "      <td>7.462533</td>\n",
              "      <td>1.93403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>107.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
              "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
              "mean       4.500000      0.000400      0.010300      0.052100      0.077000   \n",
              "std        2.872425      0.024493      0.525187      2.494315      2.208882   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        9.000000      2.000000     45.000000    218.000000    185.000000   \n",
              "\n",
              "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
              "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
              "mean       0.208600      0.349200      0.826700      2.321200      5.457800   \n",
              "std        4.669183      5.657849      8.591731     15.031508     23.359019   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max      227.000000    223.000000    247.000000    218.000000    244.000000   \n",
              "\n",
              "          ...           pixel775      pixel776      pixel777      pixel778  \\\n",
              "count     ...       10000.000000  10000.000000  10000.000000  10000.000000   \n",
              "mean      ...          34.320800     23.071900     16.432000     17.870600   \n",
              "std       ...          57.888679     49.049749     42.159665     44.140552   \n",
              "min       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "25%       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "50%       ...           0.000000      0.000000      0.000000      0.000000   \n",
              "75%       ...          55.000000      6.000000      0.000000      0.000000   \n",
              "max       ...         254.000000    252.000000    255.000000    255.000000   \n",
              "\n",
              "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
              "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
              "mean      22.860000     17.790200      8.353500      2.541600      0.629500   \n",
              "std       51.706601     45.128107     28.765769     16.417363      7.462533   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max      255.000000    255.000000    240.000000    225.000000    205.000000   \n",
              "\n",
              "          pixel784  \n",
              "count  10000.00000  \n",
              "mean       0.06560  \n",
              "std        1.93403  \n",
              "min        0.00000  \n",
              "25%        0.00000  \n",
              "50%        0.00000  \n",
              "75%        0.00000  \n",
              "max      107.00000  \n",
              "\n",
              "[8 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "9OiUOupaffUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like train set is consists 60k images and test set contains 10k images having 784 pixels i.e is 28 x 28 pixels."
      ]
    },
    {
      "metadata": {
        "id": "XUCFsGddffUc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Usefull Constants for later use\n",
        "\n",
        "These are the hyperparameters for the CNN."
      ]
    },
    {
      "metadata": {
        "id": "mRL1HsVEffUd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10 # for number of labels classes \n",
        "NUM_ROWS = 28 # num for pixels in a row \n",
        "NUM_COLS = 28 # num of pixels in a clos \n",
        "MAX_PIXEL_VALUE = 255 # highest value of a pixel \n",
        "BATCH_SIZE = 64 # batch size for train \n",
        "NUM_TRAIN_STEPS = 4000 \n",
        "NUM_TEST_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11dpuVGMffUi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot a sample image for viz"
      ]
    },
    {
      "metadata": {
        "id": "yvHIHWyjffUj",
        "colab_type": "code",
        "outputId": "a9a39a6f-d50a-4385-c369-a4dd774e4d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "for label in range(NUM_CLASSES):\n",
        "    image = train_df[train_df['label'] == label].iloc[0, 1:]\n",
        "    fig.add_subplot(2, 5, label+1)\n",
        "    plt.imshow(image.values.reshape(NUM_ROWS, NUM_COLS), cmap='gray', interpolation=None)\n",
        "\n",
        "# showing a plot \n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFcCAYAAACJJLQuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xEiVyqpBffUp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Fucntion "
      ]
    },
    {
      "metadata": {
        "id": "xJVoAGipffUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def linear mode function \n",
        "def linear_model_fn(features, labels, mode):\n",
        "    inputs = features['pixels']\n",
        "    \n",
        "    # normalize our inputs for range of 0,1\n",
        "    normalized_inputs = inputs / MAX_PIXEL_VALUE\n",
        "    \n",
        "    # linear layer to directly map to logits \n",
        "    logits = tf.layers.dense(normalized_inputs, units=NUM_CLASSES)\n",
        "    \n",
        "    # getting predictions \n",
        "    predictions = {\n",
        "        'classes':tf.argmax(input=logits, axis=1),\n",
        "        'probablities':tf.nn.softmax(logits, name='softmax_tensor')\n",
        "    }\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    \n",
        "    # calculate loss for both train and eval method \n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    \n",
        "    # configure function for train op \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
        "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "    \n",
        "    # Add eval metrics for eval operation\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\":tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
        "    }\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOF2S9eDffUu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setting up logging for our operations \n",
        "tensor_to_logs = {'predictions':'softmax_tensor'}\n",
        "logging_hook = tf.train.LoggingTensorHook(tensors=tensor_to_logs, every_n_iter=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NUg1wXPJffU3",
        "colab_type": "code",
        "outputId": "edc56800-8c80-44a3-8b00-7203ce04d6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        }
      },
      "cell_type": "code",
      "source": [
        "#@Train our linear classifier\n",
        "linear_classifier = tf.estimator.Estimator(model_fn=linear_model_fn)\n",
        "linear_classifier.train(input_fn=generate_input_fn(train_df,BATCH_SIZE), steps=NUM_TRAIN_STEPS, hooks=None)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpFVIhGs\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f905b097190>, '_model_dir': '/tmp/tmpFVIhGs', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpFVIhGs/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.8995762, step = 0\n",
            "INFO:tensorflow:global_step/sec: 158.931\n",
            "INFO:tensorflow:loss = 1.8227544, step = 100 (0.631 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.524\n",
            "INFO:tensorflow:loss = 1.4155121, step = 200 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.321\n",
            "INFO:tensorflow:loss = 1.2780411, step = 300 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.137\n",
            "INFO:tensorflow:loss = 1.2380528, step = 400 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.866\n",
            "INFO:tensorflow:loss = 1.0410519, step = 500 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.283\n",
            "INFO:tensorflow:loss = 1.0988977, step = 600 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.95\n",
            "INFO:tensorflow:loss = 0.9328191, step = 700 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.289\n",
            "INFO:tensorflow:loss = 0.9240023, step = 800 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.149\n",
            "INFO:tensorflow:loss = 0.85388887, step = 900 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.081\n",
            "INFO:tensorflow:loss = 0.9149328, step = 1000 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.424\n",
            "INFO:tensorflow:loss = 0.9061634, step = 1100 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.001\n",
            "INFO:tensorflow:loss = 0.67428434, step = 1200 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.461\n",
            "INFO:tensorflow:loss = 0.77662486, step = 1300 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.29\n",
            "INFO:tensorflow:loss = 0.67350525, step = 1400 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.188\n",
            "INFO:tensorflow:loss = 0.75535023, step = 1500 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.401\n",
            "INFO:tensorflow:loss = 0.59192556, step = 1600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.66\n",
            "INFO:tensorflow:loss = 0.8396157, step = 1700 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.117\n",
            "INFO:tensorflow:loss = 0.62735045, step = 1800 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.918\n",
            "INFO:tensorflow:loss = 0.59461033, step = 1900 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.314\n",
            "INFO:tensorflow:loss = 0.66986585, step = 2000 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.186\n",
            "INFO:tensorflow:loss = 0.74991596, step = 2100 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.4\n",
            "INFO:tensorflow:loss = 0.48519808, step = 2200 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.838\n",
            "INFO:tensorflow:loss = 0.5538951, step = 2300 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.003\n",
            "INFO:tensorflow:loss = 0.5741358, step = 2400 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.293\n",
            "INFO:tensorflow:loss = 0.6806527, step = 2500 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.098\n",
            "INFO:tensorflow:loss = 0.55357987, step = 2600 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.268\n",
            "INFO:tensorflow:loss = 0.68205696, step = 2700 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.447\n",
            "INFO:tensorflow:loss = 0.5750031, step = 2800 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.984\n",
            "INFO:tensorflow:loss = 0.77206933, step = 2900 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.995\n",
            "INFO:tensorflow:loss = 0.5813915, step = 3000 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.303\n",
            "INFO:tensorflow:loss = 0.6189547, step = 3100 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.545\n",
            "INFO:tensorflow:loss = 0.46768188, step = 3200 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.131\n",
            "INFO:tensorflow:loss = 0.76711094, step = 3300 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.08\n",
            "INFO:tensorflow:loss = 0.80196863, step = 3400 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.079\n",
            "INFO:tensorflow:loss = 0.5901946, step = 3500 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.533\n",
            "INFO:tensorflow:loss = 0.9229141, step = 3600 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.905\n",
            "INFO:tensorflow:loss = 0.54730594, step = 3700 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.44\n",
            "INFO:tensorflow:loss = 0.66920656, step = 3800 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.307\n",
            "INFO:tensorflow:loss = 0.6144906, step = 3900 (0.175 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tmpFVIhGs/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.7523348.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7f8ff6939bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "3GkGpRGgffU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate our Model for train and test case "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "54Q_pK9cffU_",
        "colab_type": "code",
        "outputId": "66a7f69d-0c27-4cb0-c28f-7c7c3989f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "linear_classifier.evaluate(input_fn=generate_input_fn(train_df, BATCH_SIZE), steps=100)\n",
        "linear_classifier.evaluate(input_fn=generate_input_fn(test_df, BATCH_SIZE), steps=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-02-03-05:29:52\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpFVIhGs/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2019-02-03-05:29:53\n",
            "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.81625, global_step = 4000, loss = 0.56049734\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/tmpFVIhGs/model.ckpt-4000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-02-03-05:29:59\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpFVIhGs/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2019-02-03-05:29:59\n",
            "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.80671877, global_step = 4000, loss = 0.59339595\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/tmpFVIhGs/model.ckpt-4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.80671877, 'global_step': 4000, 'loss': 0.59339595}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "yqKnwADGffVJ",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that our model with linear layer produces an accuracy of around ~81%"
      ]
    },
    {
      "metadata": {
        "id": "9TjD8MjmffVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN for image classifier"
      ]
    },
    {
      "metadata": {
        "id": "2Jz9JzAKffVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# make a func for cnn cls \n",
        "def cnn_model_fn(features, labels, mode):\n",
        "    \"\"\"Model function for CNN.\"\"\"\n",
        "    \n",
        "    # inputs \n",
        "    inputs = tf.reshape(features['pixels'], [-1, NUM_ROWS, NUM_COLS, 1])\n",
        "    \n",
        "    # normalized inputs \n",
        "    normalized_inputs = inputs / MAX_PIXEL_VALUE\n",
        "    \n",
        "    # making a conv layer 1 \n",
        "    conv1 = tf.layers.conv2d(inputs=normalized_inputs, filters=32, kernel_size=[3,3],padding='same', activation=tf.nn.relu)\n",
        "    \n",
        "    # making a pooling layer 1 \n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2,2], strides=2)\n",
        "    \n",
        "    # making a conv layer 2\n",
        "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "    \n",
        "    # making a pooling layer 2\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2)\n",
        "    \n",
        "    # a full dense layer \n",
        "    pool2_flat = tf.reshape(pool2, [-1, 7*7*64]) # making pool2 layer flat \n",
        "    \n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "    \n",
        "    # a drop out layer with 40% \n",
        "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    # final logits linear layer \n",
        "    logits = tf.layers.dense(inputs=dropout, units=NUM_CLASSES)\n",
        "    # getting predictions for eval and predict method \n",
        "    predictions = {\n",
        "        \"classes\":tf.argmax(input=logits, axis=1),\n",
        "        \"probablities\":tf.nn.softmax(logits=logits, name=\"softmax_tesor\")\n",
        "    }\n",
        "    \n",
        "    # if mode prediction\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode= mode, predictions=predictions)\n",
        "    \n",
        "    # computing loss for our model \n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    \n",
        "    # for train mode \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
        "        train_op = optimizer.minimize(loss = loss, global_step = tf.train.get_global_step())\n",
        "        \n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op = train_op)\n",
        "    \n",
        "    # for eval mode \n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\":tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
        "    }\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "artn_QWeffVd",
        "colab_type": "code",
        "outputId": "6ff1c6f6-278e-4171-d03c-60a3f40fefde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "# train our cnn model \n",
        "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7RsQTc\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ff21e0e90>, '_model_dir': '/tmp/tmp7RsQTc', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23_3Bto2ffVq",
        "colab_type": "code",
        "outputId": "fad205ef-8cff-4b43-ef86-f6839215d5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "cnn_classifier.train(input_fn=generate_input_fn(train_df, BATCH_SIZE), steps=NUM_TRAIN_STEPS, hooks=None)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6e030bbe3d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_TRAIN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    920\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \"\"\"\n\u001b[1;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# Inform the hooks that a new session has been created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m       return _CoordinatedSession(\n\u001b[1;32m    809\u001b[0m           \u001b[0m_HookedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.pyc\u001b[0m in \u001b[0;36mafter_create_session\u001b[0;34m(self, session, coord)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \"graph.pbtxt\")\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0msaver_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.pyc\u001b[0m in \u001b[0;36mwrite_graph\u001b[0;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     file_io.atomic_write_string_to_file(path,\n\u001b[0;32m---> 71\u001b[0;31m                                         text_format.MessageToString(graph_def))\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.pyc\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[0;34m(filename, contents, overwrite)\u001b[0m\n\u001b[1;32m    432\u001b[0m   \"\"\"\n\u001b[1;32m    433\u001b[0m   \u001b[0mtemp_pathname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tmp\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.pyc\u001b[0m in \u001b[0;36mwrite_string_to_file\u001b[0;34m(filename, file_content)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       pywrap_tensorflow.AppendToFile(\n\u001b[0;32m--> 111\u001b[0;31m           compat.as_bytes(file_content), self._writable_file, status)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eMvrMb9RffVz",
        "colab_type": "code",
        "outputId": "32e69285-0320-4bf9-9e94-b9396b7e4be0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# making eval for train and test case \n",
        "cnn_classifier.evaluate(input_fn=generate_input_fn(train_df, BATCH_SIZE), steps=100) # for train set \n",
        "cnn_classifier.evaluate(input_fn=generate_input_fn(test_df, BATCH_SIZE), steps=100) # for test set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-10-06:54:18\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpd_RjPj/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-10-06:54:23\n",
            "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9021875, global_step = 4000, loss = 0.2782911\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/tmpd_RjPj/model.ckpt-4000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-10-06:54:27\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpd_RjPj/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-10-06:54:31\n",
            "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.8996875, global_step = 4000, loss = 0.28847972\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/tmpd_RjPj/model.ckpt-4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8996875, 'global_step': 4000, 'loss': 0.28847972}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}